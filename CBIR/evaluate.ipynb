{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des méthodes avec KNN\n",
    "## Fonctionnement\n",
    "- Chaque méthode de classification extrait les descripteurs de l'image (histogrammes, ...)\n",
    "- Pour une requête donnée, on la compare avec plusieurs images de chaque classe (avec un nombre précis de plus proches voisins)\n",
    "- On calcule la distance moyenne des descripteurs de la requête avec chacune des classes\n",
    "- La distance la plus petite nous donne la classe de la requête\n",
    "## Aide\n",
    "- Un cache est utilisé pour ne pas recalculer les histogrammes, pour re-éffectuer le calcul il faut le supprimer (dossier cache)\n",
    "- Si des modifications sont effectuées dans un fichier python, il faut redémarrer le Kernel Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from DB import Database\n",
    "from color import Color\n",
    "from daisy import Daisy\n",
    "from edge import Edge\n",
    "from fusion import FeatureFusion\n",
    "\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(object):\n",
    "\n",
    "  def make_samples(self):\n",
    "    raise NotImplementedError(\"Needs to implemented this method\")\n",
    "\n",
    "# Calcule de la distance entre deux vecteurs en utilisant la methode d_type\n",
    "def distance(v1, v2, d_type='d1'):\n",
    "  assert v1.shape == v2.shape, \"shape of two vectors need to be same!\"\n",
    "\n",
    "  if d_type == 'd1':\n",
    "    return np.sum(np.absolute(v1 - v2))\n",
    "  elif d_type == 'd2':\n",
    "    return np.sum((v1 - v2) ** 2)\n",
    "  elif d_type == 'd2-norm':\n",
    "    return 2 - 2 * np.dot(v1, v2)\n",
    "  elif d_type == 'd3':\n",
    "    pass\n",
    "  elif d_type == 'd4':\n",
    "    pass\n",
    "  elif d_type == 'd5':\n",
    "    pass\n",
    "  elif d_type == 'd6':\n",
    "    pass\n",
    "  elif d_type == 'd7':\n",
    "    return 2 - 2 * np.dot(v1, v2)\n",
    "  elif d_type == 'd8':\n",
    "    return 2 - 2 * np.dot(v1, v2)\n",
    "  elif d_type == 'cosine':\n",
    "    return spatial.distance.cosine(v1, v2)\n",
    "  elif d_type == 'square':\n",
    "    return np.sum((v1 - v2) ** 2)\n",
    "\n",
    "\n",
    "def weightingDistances(results):\n",
    "  # On regroupe les distances par classes\n",
    "  resultsDf = pd.DataFrame(results)\n",
    "  resultsDfgroups =  resultsDf.groupby(\"infer_cls\")\n",
    "\n",
    "  # On calcule la distance moyenne pour chaque classe\n",
    "  classMean = []\n",
    "  for name, group in resultsDfgroups:\n",
    "    classMean.append({'infer_cls': name,'meanDis' : np.mean(group['dis'])})\n",
    "  \n",
    "  return classMean\n",
    " \n",
    "\n",
    "def infer(query, samples=None, depth=None, d_type='d1'): \n",
    "  # Verifie si les données d'entrainement sont bien fournies\n",
    "  assert samples != None , \"need to give either samples\"\n",
    "\n",
    "  # Extraction de l'image et de son histogramme de la requête\n",
    "  q_img, q_hist, q_cls = query['img'], query['hist'], query['cls']\n",
    "  results = []\n",
    "\n",
    "  # Pour chaque échantillons on les ajoutent aux résultats possible\n",
    "  for idx, sample in enumerate(samples):\n",
    "    # On extrait les descripteurs de nos échantillons\n",
    "    s_img, s_cls, s_hist = sample['img'], sample['cls'], sample['hist']\n",
    "\n",
    "    # On ajoute les distance entre le descripteur de la requête et le descripteur d'un échantillons)\n",
    "    results.append({\n",
    "                    'dis': distance(q_hist, s_hist, d_type=d_type),\n",
    "                    'infer_cls': s_cls\n",
    "                  })\n",
    "  # Résulte contient les distance entre la requête et tout les échantillons de la BDD.\n",
    "    \n",
    "  # On tri par ordre croissant (les distances les plus petites en haut)  \n",
    "  results = sorted(results, key=lambda x: x['dis'])\n",
    "\n",
    "  # On garde les depth plus proche voisins.\n",
    "  if depth and depth <= len(results):\n",
    "    results = results[:depth]\n",
    "\n",
    "  # On calcule les distances pondérées \n",
    "  weightedResults = weightingDistances(results)\n",
    "\n",
    "  # On tri les distances pondérées pour avoir la classe dont la distance pondérée est la plus petit à l'indice 0\n",
    "  weightedResults = sorted(weightedResults, key= lambda x: x['meanDis'])\n",
    "  \n",
    "  return weightedResults\n",
    "\n",
    "# Evalue un ensemble de requête  \n",
    "def evaluate_set(db, set_name, c_instance=None, depth=None, d_type='d1', h_type='region'):\n",
    "\n",
    "  assert c_instance, \"needs to give an instance of class\"\n",
    "  \n",
    "  # Calcule des échantillons du jeu train\n",
    "  samples = c_instance.make_samples(db)\n",
    "\n",
    "  results = []\n",
    "  set_data = db.get_data(set_name)\n",
    "\n",
    "  good = 0\n",
    "  # On infer la classe pour chaque requete du jeu à évaluer\n",
    "  for d in set_data.itertuples():\n",
    "    query = {\n",
    "      \"img\": getattr(d, \"img\"),\n",
    "      \"hist\": c_instance.histogram(getattr(d, \"img\"), type=h_type), # Calcule des descripteurs de la requete\n",
    "      \"cls\": getattr(d, \"cls\")\n",
    "    }\n",
    "    result = infer(query, samples=samples, depth=depth, d_type=d_type)\n",
    "    if query['cls'] == result[0]['infer_cls']:\n",
    "      good+= 1\n",
    "\n",
    "  return good, len(set_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Méthode de classification par histogramme de couleur\n",
    "La méthode classification par histogramme de couleur, génère un histogramme des composantes RGB de l'image, une image avec un histogramme proche de ceux d'autre image est considérée appartenant à la même classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache..., config=histogram_cache-region-n_bin12-n_slice3, distance=d1, depth=3\n",
      "48 classes correctes sur 60 demandées\n"
     ]
    }
   ],
   "source": [
    "db = Database(\"train\", \"validation\", \"test\")\n",
    "classification_method =  Color()\n",
    "\n",
    "# Paramètres nécessaire à l'évaluation (utiliser les même que dans le fichier color.py)\n",
    "d_type  = 'd1'      # distance type\n",
    "depth   = 3         # retrieved depth, set to None will count the ap for whole database\n",
    "\n",
    "# Evaluation de la méthode de classification\n",
    "result = evaluate_set(db, \"validation\", classification_method, depth=depth, d_type=d_type)\n",
    "\n",
    "print(\"{} classes correctes sur {} demandées\".format(result[0], result[1]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Méthode de classificiation Daisy\n",
    "La classification daisy se base sur un histogramme de gradients, il s’agit d’une détection de forme sur certaines régions de l’image (comme le montre la figure 1). L’avantage de cette classification est qu’elle est rapide à calculer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache..., config=daisy-region-n_slice2-n_orient8-step10-radius15-rings2-histograms6, distance=d1, depth=3\n",
      "47 classes correctes sur 60 demandés\n"
     ]
    }
   ],
   "source": [
    "db = Database(\"train\", \"validation\", \"test\")\n",
    "classification_method =  Daisy()\n",
    "\n",
    "# Paramètres nécessaire à l'évaluation (utiliser les même que dans le fichier daisy.py)\n",
    "d_type  = 'd1'      # distance type\n",
    "depth   = 3         # retrieved depth, set to None will count the ap for whole database\n",
    "\n",
    "# Evaluation de la méthode de classification\n",
    "result = evaluate_set(db, \"validation\", classification_method, d_type=d_type, depth=depth)\n",
    "\n",
    "print(\"{} classes correctes sur {} demandés\".format(result[0], result[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "name": "evaluate.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
