{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension des images du jeu de données\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation du jeu de données\n",
    "L'objectif de cette partie est d'augmenter la taille du jeu de données en effectuant des transformation sur les échantillons du jeu initial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40, # On tourne l'image aléatoirement de 0 à 40°\n",
    "    width_shift_range=0.2, # On fait une translation (sur la largeur) alétoire de 0 à 20% de la largeur de l'image\n",
    "    height_shift_range=0.2, # Pareil mais sur la hauteur\n",
    "    rescale=1./255, # Transforme le RGB(255) en RGB(1)\n",
    "    shear_range=0.2, # Applique aléatoirement des transformations de shearing (transvection °_°)\n",
    "    zoom_range=0.2, # Zoom aléatoire de maximum 20% du zoom initial\n",
    "    horizontal_flip=True, # Fait aléatoirement un renversement horizontal de l'image\n",
    "    fill_mode='nearest' # Type d'interpolation à appliquer pour les nouveaux pixels (qui sont créés lors des manipulations)\n",
    ")\n",
    "\n",
    "# Définie a manipulation à éffectuer sur l'image\n",
    "img = load_img('data/train/cats/cat.0.jpg')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# On applique c'est transformation au lot d'image\n",
    "i= 0 \n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "    i+=1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation pour le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# L'augmentation pour le jeu d'entrainement\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# L'augmentation pour le jeu de test\n",
    "# On ne fait que changer les composantes des couleurs (255 => 1)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place d'un modèle (convnet)\n",
    "Todo : blabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Le modèle produit des features en 3 dimensions (RGB, hauteur, largeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())  # Convertion des cara 3D en un vecteur 1D\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Utilisation de la fonction de perte 'binary_crossentropy' => TODO\n",
    "# Utilisation de l'algo d'optimisation 'rmsprop' => TODO \n",
    "# Utilisation de la metrique 'accuracy' => on mesure la précision (qu'il donne la bonne classe)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 84s 673ms/step - loss: 0.6846 - accuracy: 0.5665 - val_loss: 0.6650 - val_accuracy: 0.6075\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 83s 668ms/step - loss: 0.6687 - accuracy: 0.5940 - val_loss: 0.6217 - val_accuracy: 0.7000\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 87s 700ms/step - loss: 0.6341 - accuracy: 0.6530 - val_loss: 0.5823 - val_accuracy: 0.6562\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 84s 672ms/step - loss: 0.6390 - accuracy: 0.6430 - val_loss: 0.6458 - val_accuracy: 0.6850\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 97s 778ms/step - loss: 0.6114 - accuracy: 0.6855 - val_loss: 0.5312 - val_accuracy: 0.7138\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.6055 - accuracy: 0.6795 - val_loss: 0.6602 - val_accuracy: 0.6988\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 90s 720ms/step - loss: 0.6180 - accuracy: 0.6795 - val_loss: 0.6886 - val_accuracy: 0.7150\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 75s 600ms/step - loss: 0.5844 - accuracy: 0.6930 - val_loss: 0.5528 - val_accuracy: 0.7075\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 60s 477ms/step - loss: 0.5942 - accuracy: 0.6950 - val_loss: 0.7401 - val_accuracy: 0.7225\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 57s 457ms/step - loss: 0.5588 - accuracy: 0.7159 - val_loss: 0.4053 - val_accuracy: 0.6587\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 48s 385ms/step - loss: 0.5918 - accuracy: 0.6985 - val_loss: 0.4972 - val_accuracy: 0.6862\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 47s 375ms/step - loss: 0.5409 - accuracy: 0.7265 - val_loss: 0.5184 - val_accuracy: 0.7513\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 42s 338ms/step - loss: 0.5577 - accuracy: 0.7190 - val_loss: 0.5385 - val_accuracy: 0.7588\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 40s 317ms/step - loss: 0.5452 - accuracy: 0.7270 - val_loss: 0.7599 - val_accuracy: 0.7075\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 0.5399 - accuracy: 0.7450 - val_loss: 0.5398 - val_accuracy: 0.7862\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 40s 322ms/step - loss: 0.5536 - accuracy: 0.7290 - val_loss: 0.5497 - val_accuracy: 0.7387\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 40s 322ms/step - loss: 0.5383 - accuracy: 0.7340 - val_loss: 0.5607 - val_accuracy: 0.7825\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 40s 318ms/step - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.4163 - val_accuracy: 0.7987\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 39s 314ms/step - loss: 0.5511 - accuracy: 0.7465 - val_loss: 0.5943 - val_accuracy: 0.7613\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 40s 323ms/step - loss: 0.5399 - accuracy: 0.7315 - val_loss: 0.6920 - val_accuracy: 0.7713\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 41s 326ms/step - loss: 0.5364 - accuracy: 0.7510 - val_loss: 0.2273 - val_accuracy: 0.7837\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 43s 344ms/step - loss: 0.5431 - accuracy: 0.7435 - val_loss: 0.4263 - val_accuracy: 0.7850\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.5152 - accuracy: 0.7565 - val_loss: 0.4385 - val_accuracy: 0.7725\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 41s 329ms/step - loss: 0.5350 - accuracy: 0.7460 - val_loss: 0.8703 - val_accuracy: 0.7588\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 43s 343ms/step - loss: 0.5261 - accuracy: 0.7545 - val_loss: 0.4087 - val_accuracy: 0.7663\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 45s 362ms/step - loss: 0.4998 - accuracy: 0.7680 - val_loss: 0.4686 - val_accuracy: 0.8000\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.5162 - accuracy: 0.7410 - val_loss: 0.6445 - val_accuracy: 0.7550\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 68s 546ms/step - loss: 0.5117 - accuracy: 0.7700 - val_loss: 0.4301 - val_accuracy: 0.7812\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 56s 447ms/step - loss: 0.5222 - accuracy: 0.7530 - val_loss: 0.5618 - val_accuracy: 0.7900\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 46s 365ms/step - loss: 0.5196 - accuracy: 0.7590 - val_loss: 0.4218 - val_accuracy: 0.7675\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 51s 405ms/step - loss: 0.5354 - accuracy: 0.7580 - val_loss: 1.1882 - val_accuracy: 0.6925\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 49s 394ms/step - loss: 0.5081 - accuracy: 0.7720 - val_loss: 0.3534 - val_accuracy: 0.7576\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 44s 348ms/step - loss: 0.4806 - accuracy: 0.7740 - val_loss: 0.8603 - val_accuracy: 0.7475\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 42s 336ms/step - loss: 0.5164 - accuracy: 0.7630 - val_loss: 1.0197 - val_accuracy: 0.7625\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 40s 318ms/step - loss: 0.5121 - accuracy: 0.7765 - val_loss: 0.3824 - val_accuracy: 0.7925\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 39s 309ms/step - loss: 0.4944 - accuracy: 0.7845 - val_loss: 0.3440 - val_accuracy: 0.7800\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 38s 303ms/step - loss: 0.4995 - accuracy: 0.7715 - val_loss: 0.5903 - val_accuracy: 0.7800\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.4739 - accuracy: 0.7945 - val_loss: 0.3692 - val_accuracy: 0.8100\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 39s 310ms/step - loss: 0.4904 - accuracy: 0.7695 - val_loss: 0.3306 - val_accuracy: 0.7975\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 38s 303ms/step - loss: 0.4847 - accuracy: 0.7765 - val_loss: 0.4412 - val_accuracy: 0.7675\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 38s 305ms/step - loss: 0.4681 - accuracy: 0.7805 - val_loss: 0.7266 - val_accuracy: 0.8037\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 0.4951 - accuracy: 0.7825 - val_loss: 0.4949 - val_accuracy: 0.7837\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 0.4919 - accuracy: 0.7840 - val_loss: 0.5232 - val_accuracy: 0.7862\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 41s 327ms/step - loss: 0.4710 - accuracy: 0.7845 - val_loss: 0.3470 - val_accuracy: 0.7763\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 38s 301ms/step - loss: 0.4987 - accuracy: 0.7705 - val_loss: 0.4880 - val_accuracy: 0.7688\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 37s 298ms/step - loss: 0.4902 - accuracy: 0.7756 - val_loss: 0.4788 - val_accuracy: 0.7900\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.4958 - accuracy: 0.7700 - val_loss: 0.5210 - val_accuracy: 0.7937\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 40s 318ms/step - loss: 0.4739 - accuracy: 0.7810 - val_loss: 0.6362 - val_accuracy: 0.8125\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.4544 - accuracy: 0.7925 - val_loss: 0.6297 - val_accuracy: 0.7925\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 38s 301ms/step - loss: 0.4856 - accuracy: 0.7785 - val_loss: 0.2441 - val_accuracy: 0.7775\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('cnn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement d'une image de test\n",
    "test_img_path = \"data/train/cats/cat.21.jpg\"\n",
    "test_img = load_img(test_img_path, target_size=(150, 150))\n",
    "test_img_array = img_to_array(test_img)\n",
    "test_img_array = np.expand_dims(test_img_array, axis = 0)\n",
    "\n",
    "# Prédiction de la classe\n",
    "predict = model.predict(test_img_array)\n",
    "print(predict)\n",
    "train_generator.class_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
